{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Project Starter</h2>\n",
    "\n",
    "<p>This notebook provides code to build machine learning experiments very fast.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale, minmax_scale, normalize, binarize\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, VarianceThreshold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC, SVR, LinearSVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.model_selection import LeaveOneOut, KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Input data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manual_input(var, val):\n",
    "    col_dict = {var[index]:val[index] for index in range(len(var))}\n",
    "    return pd.DataFrame.from_dict(col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# From csv\n",
    "if(False):\n",
    "    data = pd.read_csv('')\n",
    "\n",
    "# Manually\n",
    "if(False):    \n",
    "    var = []\n",
    "    val = [[],[]]\n",
    "    data = manual_input(var, val)\n",
    "\n",
    "# Sample\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Missing data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Are there missing data?\n",
    "print(\"# Missing = %d\" % data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill data?\n",
    "\n",
    "# Backward fill \n",
    "if(False):\n",
    "    data.fillna(method='bfill', inplace=True)\n",
    "    \n",
    "# Forward fill\n",
    "if(False):\n",
    "    data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Fill with mean of each column\n",
    "if(False):\n",
    "    data.fillna(data.mean(), inplace=True)\n",
    "    \n",
    "# Fill with mediana of each column\n",
    "if(False):\n",
    "    data.fillna(data.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Standardization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardization of datasets\n",
    "\n",
    "# Scale with zero mean and unit variance\n",
    "if(False):\n",
    "    data.iloc[:,:] = scale(data)\n",
    "    \n",
    "# Scale features to range 0-1\n",
    "if(False):\n",
    "    data.iloc[:,:] = minmax_scale(data)\n",
    "\n",
    "# Normalize each row using L2\n",
    "if(False):\n",
    "    data.iloc[:,:] = normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Thresholding</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Thresholding numerical features\n",
    "\n",
    "# Binarize all values with threshold equals 0 \n",
    "if(False):\n",
    "    data.iloc[:,:] = binarize(data, threshold=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Categorical features (NT)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding \n",
    "cat_to_onehot = []\n",
    "cat_to_int = list(data.columns.values)\n",
    "total = cat_to_int + cat_to_onehot\n",
    "\n",
    "# Perform conversion of object columns to categorical columns\n",
    "if(True):\n",
    "    data = data.apply(lambda s: s.astype('category') if(s.name in total) else s)\n",
    "\n",
    "# Categorical to one hot encoding \n",
    "if(False):\n",
    "    data = pd.get_dummies(data, columns = cat_to_onehot)\n",
    "    \n",
    "# Categorical to int\n",
    "if(True):\n",
    "    data = data.apply(lambda s: s.cat.codes if(s.name in cat_to_int) else s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Feature selection (NT)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Functions available to perform feature selection:</p>\n",
    "<ul>\n",
    "    <li>regression problems: f_regression, mutual_info_regression</li>\n",
    "    <li>classification problems: chi2, f_classif, mutual_info_classif</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Must specify features matrix and target vector!\n",
    "\n",
    "# Select features with variance above a threshold\n",
    "if(False):\n",
    "    data = VarianceThreshold(threshold=0.0).fit_transform(data)\n",
    "\n",
    "# Select K best variables (fill function and k parameters!)\n",
    "if(False):\n",
    "    data = SelectKBest(function, k=10).fit_transform(data, data)\n",
    "    \n",
    "# Select X percent best features (fill function and percentile (how much to keep) parameters!)\n",
    "if(False):\n",
    "    data = SelectKBest(function, percentile=50).fit_transform(data.X, data.Y)\n",
    "    \n",
    "# Perform PCA (principal component analysis)\n",
    "if(False):\n",
    "    pass\n",
    "    # PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Correlation coefficient</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Must specify features matrix and target vector.\n",
    "\n",
    "# Person's coefficient\n",
    "if(False):\n",
    "    person = []\n",
    "    map(lambda s: person.append(X[s].corr(Y, method='person')), X.columns)\n",
    "    \n",
    "# Spearman's coefficient\n",
    "if(False):\n",
    "    spearman = []\n",
    "    map(lambda s: person.append(X[s].corr(Y, method='spearman')), X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "val = LeaveOneOut()\n",
    "val = KFold() \n",
    "\n",
    "for train_index, test_index in val.split(X):\n",
    "print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear regression without regularization\n",
    "\n",
    "model = LinearRegression(jobs=-1)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "regression_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear regression with Ridge (L2) regularization\n",
    "\n",
    "model = Ridge(alpha=1.0, random_state=1)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "regression_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear regression with Lasso (L1) regularization\n",
    "\n",
    "model = Lasso(alpha=1.0, random_state=1)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "regression_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear regression with Elastic-net regularization\n",
    "\n",
    "model = ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=1)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "regression_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Support vector regressor with linear kernel\n",
    "\n",
    "model = LinearSVR(epsilon=0.0, loss='epsilon_insensitive', C=1.0, random_state=1)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "regression_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Support vector regressor with other kernels \n",
    "\n",
    "model = SVR(kernel='rbf', gamma='auto', epsilon=0.1, C=1.0, random_state=1, cache_size=1000)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "regression_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K Nearest neighbors regressor\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=5, weights='uniform', algorithm='auto', \\\n",
    "                            leaf_size=30, p=2, metric='minkowski', n_jobs=-1)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "regression_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tree regressor\n",
    "\n",
    "model = DecisionTreeRegressor(criterion='mse', splitter='best', max_depth=None, min_samples_split=2, \\\n",
    "                              min_samples_leaf=1, min_weight_fraction_leaf=0.0, \\\n",
    "                              random_state=1, max_leaf_nodes=None, min_impurity_decrease=0.0, \\\n",
    "                              min_impurity_split=None)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "regression_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural network regressor\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes=(100,), activation='relu', \\\n",
    "                     learning_rate='constant', learning_rate_init=0.001, random_state=1)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "regression_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random forest regressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=10, criterion='mse', max_depth=None, \\\n",
    "                              min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \\\n",
    "                              max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, \\\n",
    "                              min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=-1, \\\n",
    "                              random_state=1)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "regression_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classification</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression with regularization\n",
    "\n",
    "model = LogisticRegression(penalty='l2', C=1.0, random_state=1, n_jobs=-1)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "classification_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Support vector classifier with linear kernel\n",
    "\n",
    "model = LinearSVC(penalty='l2', C=1.0, random_state=1)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "classification_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Support vector classifier with other kernels \n",
    "\n",
    "model = SVC(kernel='rbf', gamma='auto', C=1.0, random_state=1, cache_size=1000)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "classification_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K nearest neighbors classifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', \\\n",
    "                             leaf_size=30, p=2, metric='minkowski', n_jobs=-1)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "classification_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive bayes classifier using normal distribution\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "classification_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive bayes classifier using multinomial distribution\n",
    "\n",
    "model = MultinomialNB(alpha=0.000001)\n",
    "model.fit(data.loc[:, data.columns != 'classe'], data['classe'])\n",
    "y_pred = model.predict_proba([[1,2,1,1]])\n",
    "y_pred\n",
    "#classification_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive bayes classifier using Bernoulli distribution\n",
    "\n",
    "model = BernoulliNB(alpha=1.0, binarize=0.0)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "classification_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree classifier\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=None, \\\n",
    "                               min_samples_split=2, min_samples_leaf=1, \\\n",
    "                               min_weight_fraction_leaf=0.0, max_features=None, \\\n",
    "                               random_state=1, max_leaf_nodes=None, \\\n",
    "                               min_impurity_decrease=0.0, min_impurity_split=None, \\\n",
    "                               presort=False)\n",
    "model.fit(data.loc[:, data.columns != 'espera'], data['espera'])\n",
    "y_pred = model.predict([[1,1,1,0]])\n",
    "print(y_pred)\n",
    "#classification_metrics(y_pred, Yva) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural network classifier\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', \\\n",
    "                      learning_rate='constant', learning_rate_init=0.001, random_state=1)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "regression_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random forest classifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, \\\n",
    "                               min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \\\n",
    "                               max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, \\\n",
    "                               min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=-1, \\\n",
    "                               random_state=1)\n",
    "model.fit(Xtr, Ytr)\n",
    "y_pred = model.predict(Xva)\n",
    "regression_metrics(y_pred, Yva)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Clustering</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Means\n",
    "\n",
    "model = KMeans(n_clusters=2, init='k-means++', max_iter=5, tol=0.0001, \\\n",
    "               random_state=1, copy_x=True, \\\n",
    "               n_jobs=-1, algorithm='auto')\n",
    "model.fit([[1,1],[1,2],[2,1],[2,2],[5,1],[6,1],[5,2]])\n",
    "print(model.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "model = DBSCAN(eps=0.5, min_samples=5, metric='euclidean', \\\n",
    "               metric_params=None, algorithm='auto', leaf_size=30, \\\n",
    "               p=None, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hierar..\n",
    "\n",
    "model = AgglomerativeClustering(n_clusters=2, affinity='euclidean', memory=None, \\\n",
    "                                connectivity=None, compute_full_tree='auto', \\\n",
    "                                linkage='ward', pooling_func=<function mean at 0x7f0ea81166a8>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Results / metrics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression_metrics(y_pred, Yva):\n",
    "    print('MAE = ' + str(mean_absolute_error(Yva, y_pred)))\n",
    "    print('MSE = ' + str(mean_squared_error(Yva, y_pred)))\n",
    "    print('MAE = ' + str(r2_score(Yva, y_pred)))\n",
    "    \n",
    "def regression_metrics(y_pred, Yva):\n",
    "    print('MAE = ' + str(accuracy_score(Yva, y_pred)))\n",
    "    print('MSE = ' + str(f1_score(Yva, y_pred)))\n",
    "    print('MAE = ' + str(precision_score(Yva, y_pred)))\n",
    "    print('MAE = ' + str(recall_score(Yva, y_pred)))\n",
    "    print('MAE = ' + str(roc_auc_score(Yva, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
