{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeros = pd.read_csv(\"classificacao_Q4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.696199</td>\n",
       "      <td>-0.792598</td>\n",
       "      <td>-0.349427</td>\n",
       "      <td>-0.464560</td>\n",
       "      <td>3.187014</td>\n",
       "      <td>0.035976</td>\n",
       "      <td>1.033274</td>\n",
       "      <td>-1.504968</td>\n",
       "      <td>0.204693</td>\n",
       "      <td>1.691204</td>\n",
       "      <td>...</td>\n",
       "      <td>1.488142</td>\n",
       "      <td>-0.686337</td>\n",
       "      <td>2.084970</td>\n",
       "      <td>-0.685140</td>\n",
       "      <td>-2.049451</td>\n",
       "      <td>2.015426</td>\n",
       "      <td>1.158477</td>\n",
       "      <td>-0.309441</td>\n",
       "      <td>-1.549833</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.236696</td>\n",
       "      <td>-2.202342</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>1.497700</td>\n",
       "      <td>-0.069758</td>\n",
       "      <td>-2.467088</td>\n",
       "      <td>1.126529</td>\n",
       "      <td>-0.570557</td>\n",
       "      <td>2.079251</td>\n",
       "      <td>-1.882632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405567</td>\n",
       "      <td>0.509564</td>\n",
       "      <td>1.374071</td>\n",
       "      <td>-0.016943</td>\n",
       "      <td>-0.429280</td>\n",
       "      <td>-0.895016</td>\n",
       "      <td>1.259566</td>\n",
       "      <td>-0.354139</td>\n",
       "      <td>0.806797</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.436683</td>\n",
       "      <td>1.563816</td>\n",
       "      <td>-0.895999</td>\n",
       "      <td>-0.580425</td>\n",
       "      <td>0.311060</td>\n",
       "      <td>-0.187369</td>\n",
       "      <td>0.805249</td>\n",
       "      <td>-2.399522</td>\n",
       "      <td>-0.578818</td>\n",
       "      <td>1.586981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933578</td>\n",
       "      <td>-1.285978</td>\n",
       "      <td>0.503162</td>\n",
       "      <td>0.204829</td>\n",
       "      <td>-0.753835</td>\n",
       "      <td>0.290033</td>\n",
       "      <td>1.721487</td>\n",
       "      <td>1.304518</td>\n",
       "      <td>0.478903</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.425908</td>\n",
       "      <td>0.400055</td>\n",
       "      <td>-0.305038</td>\n",
       "      <td>-0.930251</td>\n",
       "      <td>-2.214549</td>\n",
       "      <td>1.763379</td>\n",
       "      <td>-0.239868</td>\n",
       "      <td>-2.058891</td>\n",
       "      <td>-1.006533</td>\n",
       "      <td>-2.156839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.849927</td>\n",
       "      <td>1.402768</td>\n",
       "      <td>0.393653</td>\n",
       "      <td>-1.466818</td>\n",
       "      <td>0.152257</td>\n",
       "      <td>-4.004950</td>\n",
       "      <td>0.676342</td>\n",
       "      <td>-1.927319</td>\n",
       "      <td>1.959032</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.186156</td>\n",
       "      <td>-0.975764</td>\n",
       "      <td>0.594660</td>\n",
       "      <td>-1.181980</td>\n",
       "      <td>-1.443414</td>\n",
       "      <td>-0.797651</td>\n",
       "      <td>-1.252608</td>\n",
       "      <td>-0.060452</td>\n",
       "      <td>0.130702</td>\n",
       "      <td>-2.343517</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.444435</td>\n",
       "      <td>-1.818126</td>\n",
       "      <td>0.446574</td>\n",
       "      <td>0.239328</td>\n",
       "      <td>0.802939</td>\n",
       "      <td>-2.035289</td>\n",
       "      <td>-1.433793</td>\n",
       "      <td>-0.218596</td>\n",
       "      <td>0.619317</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  1.696199 -0.792598 -0.349427 -0.464560  3.187014  0.035976  1.033274   \n",
       "1 -0.236696 -2.202342  0.024023  1.497700 -0.069758 -2.467088  1.126529   \n",
       "2 -0.436683  1.563816 -0.895999 -0.580425  0.311060 -0.187369  0.805249   \n",
       "3  1.425908  0.400055 -0.305038 -0.930251 -2.214549  1.763379 -0.239868   \n",
       "4 -0.186156 -0.975764  0.594660 -1.181980 -1.443414 -0.797651 -1.252608   \n",
       "\n",
       "         x7        x8        x9   ...         x91       x92       x93  \\\n",
       "0 -1.504968  0.204693  1.691204   ...    1.488142 -0.686337  2.084970   \n",
       "1 -0.570557  2.079251 -1.882632   ...    0.405567  0.509564  1.374071   \n",
       "2 -2.399522 -0.578818  1.586981   ...    0.933578 -1.285978  0.503162   \n",
       "3 -2.058891 -1.006533 -2.156839   ...   -0.849927  1.402768  0.393653   \n",
       "4 -0.060452  0.130702 -2.343517   ...   -1.444435 -1.818126  0.446574   \n",
       "\n",
       "        x94       x95       x96       x97       x98       x99  target  \n",
       "0 -0.685140 -2.049451  2.015426  1.158477 -0.309441 -1.549833     4.0  \n",
       "1 -0.016943 -0.429280 -0.895016  1.259566 -0.354139  0.806797     5.0  \n",
       "2  0.204829 -0.753835  0.290033  1.721487  1.304518  0.478903     3.0  \n",
       "3 -1.466818  0.152257 -4.004950  0.676342 -1.927319  1.959032     8.0  \n",
       "4  0.239328  0.802939 -2.035289 -1.433793 -0.218596  0.619317     9.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeros.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x0        x1        x2        x3        x4        x5        x6  \\\n",
      "0  1.696199 -0.792598 -0.349427 -0.464560  3.187014  0.035976  1.033274   \n",
      "1 -0.236696 -2.202342  0.024023  1.497700 -0.069758 -2.467088  1.126529   \n",
      "2 -0.436683  1.563816 -0.895999 -0.580425  0.311060 -0.187369  0.805249   \n",
      "3  1.425908  0.400055 -0.305038 -0.930251 -2.214549  1.763379 -0.239868   \n",
      "4 -0.186156 -0.975764  0.594660 -1.181980 -1.443414 -0.797651 -1.252608   \n",
      "\n",
      "         x7        x8        x9    ...          x90       x91       x92  \\\n",
      "0 -1.504968  0.204693  1.691204    ...    -0.534360  1.488142 -0.686337   \n",
      "1 -0.570557  2.079251 -1.882632    ...     0.498207  0.405567  0.509564   \n",
      "2 -2.399522 -0.578818  1.586981    ...    -2.630024  0.933578 -1.285978   \n",
      "3 -2.058891 -1.006533 -2.156839    ...    -0.260665 -0.849927  1.402768   \n",
      "4 -0.060452  0.130702 -2.343517    ...     1.098563 -1.444435 -1.818126   \n",
      "\n",
      "        x93       x94       x95       x96       x97       x98       x99  \n",
      "0  2.084970 -0.685140 -2.049451  2.015426  1.158477 -0.309441 -1.549833  \n",
      "1  1.374071 -0.016943 -0.429280 -0.895016  1.259566 -0.354139  0.806797  \n",
      "2  0.503162  0.204829 -0.753835  0.290033  1.721487  1.304518  0.478903  \n",
      "3  0.393653 -1.466818  0.152257 -4.004950  0.676342 -1.927319  1.959032  \n",
      "4  0.446574  0.239328  0.802939 -2.035289 -1.433793 -0.218596  0.619317  \n",
      "\n",
      "[5 rows x 100 columns]\n",
      "(1500, 100)\n",
      "   target\n",
      "0     4.0\n",
      "1     5.0\n",
      "2     3.0\n",
      "3     8.0\n",
      "4     9.0\n",
      "(1500, 1)\n"
     ]
    }
   ],
   "source": [
    "numeros_x = numeros.iloc[:,:-1]\n",
    "print(numeros_x.head())\n",
    "print(numeros_x.shape)\n",
    "\n",
    "\n",
    "numeros_y = numeros.iloc[:,-1:]\n",
    "print(numeros_y.head())\n",
    "print(numeros_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_mlp(cv,data_x,data_y):\n",
    "    scores_train= []\n",
    "    scores_test= []\n",
    "    acc_train = []\n",
    "    acc_test = []\n",
    "    #auc_train = []\n",
    "    #auc_test = []\n",
    "    precision_test = []\n",
    "    precision_train = []\n",
    "    recall_test = []\n",
    "    recall_train = []\n",
    "    f1_test = []\n",
    "    f1_train = []\n",
    "    y_pred_train = []\n",
    "    y_pred_test = []\n",
    "    \n",
    "    for train_idx, test_idx in cv.split(data_x):\n",
    "        X_train, X_test = data_x.iloc[train_idx], data_x.iloc[test_idx] \n",
    "        y_train, y_test = data_y.iloc[train_idx], data_y.iloc[test_idx]\n",
    "        #print(test_idx)\n",
    "        model = MLPClassifier(hidden_layer_sizes=(100, ), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', \n",
    "                           learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "                           random_state=0, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                           nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, \n",
    "                           beta_2=0.999, epsilon=1e-08)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        precision_test.append(precision_score(y_test, y_pred_test,average='micro'))\n",
    "        precision_train.append(precision_score(y_train, y_pred_train,average='micro'))\n",
    "        recall_test.append(recall_score(y_test, y_pred_test,average='micro'))\n",
    "        recall_train.append(recall_score(y_train, y_pred_train,average='micro'))\n",
    "        f1_test.append(f1_score(y_test, y_pred_test,average='micro'))\n",
    "        f1_train.append(f1_score(y_train, y_pred_train,average='micro'))\n",
    "        acc_test.append(accuracy_score(y_test, y_pred_test))\n",
    "        acc_train.append(accuracy_score(y_train, y_pred_train))\n",
    "        \n",
    "        #auc_train.append(roc_auc_score(y_train, y_pred_train))\n",
    "        #auc_test.append(roc_auc_score(y_test, y_pred_test))\n",
    "        \n",
    "    print(\"TRAIN :\")\n",
    "    print('Accuracy Mean', np.mean(acc_train))\n",
    "    print('Precision Mean', np.mean(precision_train))\n",
    "    print('Recall Mean', np.mean(recall_train))\n",
    "    print('F1 Mean', np.mean(f1_train))\n",
    "    \n",
    "    print(\"TEST :\")\n",
    "    #print('Accuracy List Train: ', acc_test)\n",
    "    print('Accuracy Mean', np.mean(acc_test))\n",
    "    print('Precision Mean', np.mean(precision_test))\n",
    "    print('Recall Mean', np.mean(recall_test))\n",
    "    print('F1 Mean', np.mean(f1_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN :\n",
      "Accuracy Mean 1.0\n",
      "Precision Mean 1.0\n",
      "Recall Mean 1.0\n",
      "F1 Mean 1.0\n",
      "TEST :\n",
      "Accuracy Mean 0.6266666666666667\n",
      "Precision Mean 0.6266666666666667\n",
      "Recall Mean 0.6266666666666667\n",
      "F1 Mean 0.6266666666666667\n",
      "Mean cval_score (Test):  0.6266666666666667\n",
      "['fit_time', 'score_time', 'test_score', 'train_score']\n",
      "Train:  1.0\n",
      "Test:  0.6266666666666667\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10,shuffle=False)\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(100, ), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', \n",
    "                           learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "                           random_state=0, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                           nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, \n",
    "                           beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "cross_validate_mlp(kf, numeros_x, numeros_y)\n",
    "\n",
    "cval = cross_val_score(model, numeros_x, numeros_y, cv=kf,scoring='accuracy')\n",
    "print(\"Mean cval_score (Test): \", np.mean(cval))\n",
    "\n",
    "cvalidate = cross_validate(model,numeros_x,numeros_y,cv=kf,scoring='accuracy', return_train_score=True)\n",
    "print(sorted(cvalidate.keys()))\n",
    "print(\"Train: \",np.mean(cvalidate['train_score']))\n",
    "print(\"Test: \",np.mean(cvalidate['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
